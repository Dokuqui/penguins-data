# üêß Rapport Technique : Architecture Big Data Distribu√©e & MLOps

**Projet :** Classification Distribu√©e des Manchots (Palmer Penguins) avec Architecture Multi-NoSQL

**Date :** 17 F√©vrier 2026

**Auteur :** Semenov Illia

**Stack Technique :** Docker, Apache Spark, MongoDB, Cassandra, Redis, FastAPI, Streamlit

**URL du Dashboard :** [http://91.134.143.137:8501/]()

---

## üìÖ Table des Mati√®res

1. **Introduction & Objectifs**
2. **Architecture du Syst√®me**
3. **Mod√©lisation des Donn√©es (NoSQL)**

   3.1 MongoDB (Document Store)
   3.2 Cassandra (Column-Family Store)
   3.3 Redis (Cache Key-Value)

4. **Analyse Statistique & R√©gression**

   4.1 Statistiques Descriptives
   4.2 Mod√©lisation par R√©gression Lin√©aire

5. **Pipeline Machine Learning (Spark MLlib)**

   5.1 Pr√©traitement et Feature Engineering
   5.2 Algorithme de Classification
   5.3 Inf√©rence Hybride (Batch vs Temps-r√©el)

6. **Observabilit√© MLOps**

   6.1 D√©tection de Drift (D√©rive de donn√©es)
   6.2 Monitoring de la Performance

7. **Benchmarks & Analyse de Performance**
8. **Conclusion & Perspectives de Scalabilit√©**

---

## 1. Introduction & Objectifs

Ce projet vise √† concevoir une **architecture Big Data r√©siliente et scalable** capable de g√©rer le cycle de vie complet d'un mod√®le de Machine Learning : de l'ingestion de donn√©es brutes √† l'inf√©rence en temps r√©el.

L'objectif principal est de classifier les esp√®ces de manchots de l'archipel Palmer (*Adelie, Chinstrap, Gentoo*) en utilisant leurs mesures biom√©triques. Au-del√† de la simple classification, ce projet r√©pond aux exigences d'analyse exploratoire et de mod√©lisation pr√©dictive (r√©gression), tout en d√©montrant l'orchestration de plusieurs moteurs NoSQL pour satisfaire les **3 V du Big Data** :

* **Vari√©t√©** : Gestion de donn√©es semi-structur√©es via MongoDB.
* **Volume** : Stockage distribu√© et partitionn√© via Cassandra.
* **V√©locit√©** : Inf√©rence temps-r√©el (< 1ms) via Redis et FastAPI.

---

## 2. Architecture du Syst√®me

Le syst√®me repose sur une architecture conteneuris√©e (Docker) compos√©e de quatre services interconnect√©s :

1. **Couche d'Ingestion (ETL Python) :**

   * R√©cup√©ration du dataset brut (CSV).
   * Nettoyage (gestion des `NA`, normalisation des noms de colonnes).
   * Dispatch vers les bases de donn√©es (MongoDB pour le "Data Lake", Cassandra pour le "Data Warehouse").

2. **Couche de Traitement (Apache Spark 3.5 & Scikit-Learn) :**

   * Lecture distribu√©e depuis MongoDB.
   * Transformation des features (`VectorAssembler`, `StandardScaler`).
   * Entra√Ænement du mod√®le de classification `RandomForestClassifier` (Spark).
   * Mod√©lisation de r√©gression lin√©aire interactive (Scikit-Learn).

3. **Couche de Service (API & Cache) :**

   * **Redis :** Cache "Hot Path" pour servir les pr√©dictions d√©j√† calcul√©es instantan√©ment.
   * **FastAPI :** Microservice exposant deux endpoints (Lookup et Inf√©rence Custom). Il h√©berge un "Shadow Model" pour traiter les nouvelles donn√©es √† la vol√©e.

4. **Couche de Visualisation (Streamlit) :**

   * Dashboard interactif accessible publiquement sur **[http://91.134.143.137:8501/]()**. Il inclut le monitoring MLOps, le laboratoire de r√©gression et les statistiques descriptives.

---

## 3. Mod√©lisation des Donn√©es (NoSQL)

Le choix d'une architecture polyglotte (Multi-NoSQL) est justifi√© par le besoin d'optimiser chaque √©tape du traitement.

### 3.1 MongoDB (Document Store)

**R√¥le :** Data Lake op√©rationnel & flexibilit√© de sch√©ma.

Nous avons opt√© pour une mod√©lisation **orient√©e document** avec imbrication (`embedding`). Contrairement √† un mod√®le relationnel normalis√© (3NF), nous regroupons toutes les mesures biom√©triques dans un sous-document `features`.

* **Structure JSON :**

```json
{
  "_id": "ObjectId(...)",
  "penguin_id": "P1024",
  "species": "Gentoo",
  "island": "Biscoe",
  "features": {  // Encapsulation pour lecture atomique
    "bill_length": 45.2,
    "bill_depth": 14.8,
    "flipper_length": 212,
    "body_mass": 5200
  },
  "sex": "FEMALE",
  "year": 2020
}
```

* **Justification Scalabilit√© :** Ce mod√®le permet d'ajouter de nouvelles features (ex: `gps_coordinates` ou `blood_sample`) sans casser le sch√©ma existant ni n√©cessiter de migration lourde (Schema Evolution).

### 3.2 Cassandra (Column-Family Store)

**R√¥le :** Stockage analytique haute disponibilit√© & "Source of Truth".

Cassandra est optimis√© pour les √©critures massives et la tol√©rance aux pannes. La mod√©lisation repose sur les requ√™tes (Query-Driven Modeling).

* **Sch√©ma CQL :**

```sql
CREATE TABLE penguin_ks.penguins_by_island (
    island text,          -- PARTITION KEY
    species text,         -- CLUSTERING KEY 1
    penguin_id text,      -- CLUSTERING KEY 2
    bill_length float,
    body_mass int,
    prediction double,
    PRIMARY KEY ((island), species, penguin_id)
);
```

* **Strat√©gie de Partitionnement (`island`) :**
  * Le choix de l'√Æle comme **Partition Key** garantit que toutes les donn√©es d'une zone g√©ographique sont stock√©es sur les m√™mes n≈ìuds physiques. Cela permet des requ√™tes d'agr√©gation g√©ographique extr√™mement rapides.
  * La **Clustering Key** (`species`, `penguin_id`) trie les donn√©es sur le disque, optimisant les recherches par plage (Range Scans).

### 3.3 Redis (Key-Value Store)

**R√¥le :** Cache de pr√©diction temps-r√©el (Low Latency).

* **Structure :** Cl√© = `penguin_id`, Valeur = `prediction_float`.
* **TTL (Time-To-Live) :** Configur√© √† 1 heure (3600s) pour garantir la fra√Æcheur des donn√©es tout en d√©chargeant les bases persistantes.

---

## 4. Analyse Statistique & R√©gression

Pour r√©pondre aux besoins d'analyse exploratoire, une section d√©di√©e a √©t√© int√©gr√©e au Dashboard.

### 4.1 Statistiques Descriptives

Le syst√®me calcule automatiquement les indicateurs cl√©s (Moyenne, M√©diane, √âcart-type, Min/Max) pour l'ensemble des variables num√©riques (`bill_length`, `body_mass`, etc.).

* Visualisation de la r√©partition par √éle et par Sexe.
* Scatter Plots sp√©cifiques : *Longueur vs Profondeur du bec* (par Esp√®ce) et *Longueur nageoire vs Masse* (par Sexe).

### 4.2 Mod√©lisation par R√©gression Lin√©aire

Un laboratoire interactif permet d'ex√©cuter des r√©gressions (Simples et Multiples) pour pr√©dire la masse corporelle (`body_mass_g`).

* **M√©thodologie :** S√©paration Train/Test (80/20), entra√Ænement d'un mod√®le OLS.
* **M√©triques :** Affichage du coefficient  et de l'erreur quadratique moyenne (MSE).
* **R√©sultats :** L'analyse des coefficients confirme que la `flipper_length` est la variable la plus corr√©l√©e positivement √† la masse corporelle.

---

## 5. Pipeline Machine Learning (Spark MLlib)

Le c≈ìur du traitement de classification est un job Spark distribu√© (`spark_ml.py`).

### 5.1 Pr√©traitement et Feature Engineering

L'√©tape critique identifi√©e a √©t√© la **mise √† l'√©chelle des donn√©es**.

* **Probl√®me :** La variable `body_mass` (~4000 g) a une magnitude 200x sup√©rieure √† `bill_depth` (~18 mm).
* **Solution :** Application d'un `StandardScaler` (Z-Score normalization) dans le pipeline Spark pour ramener toutes les features √† une moyenne de 0 et un √©cart-type de 1.

### 5.2 Algorithme de Classification

* **Mod√®le :** `RandomForestClassifier`
* **Hyperparam√®tres :** `numTrees=20` (stabilisation de la variance), `maxDepth=5` (limitation du sur-apprentissage).
* **R√©sultats :** Le mod√®le atteint une pr√©cision √©lev√©e (>95%), distinguant clairement les *Gentoo* (massifs) des autres esp√®ces.

### 5.3 Inf√©rence Hybride

Pour une application pleinement fonctionnelle, deux modes d'inf√©rence coexistent :

1. **Batch Inference (Spark) :** Calcul de nuit sur l'historique, r√©sultats pouss√©s dans Cassandra.
2. **Real-time Inference (API) :** Un mod√®le "Shadow" (Scikit-Learn) entra√Æn√© au d√©marrage de l'API permet de pr√©dire l'esp√®ce d'un manchot *inconnu* en < 50ms.

---

## 6. Observabilit√© MLOps

Un syst√®me Big Data en production doit √™tre surveill√©.

### 6.1 D√©tection de Drift (D√©rive de donn√©es)

Les mod√®les ML se d√©gradent quand les donn√©es r√©elles changent.

* **M√©thode :** Test de Kolmogorov-Smirnov (KS Test).
* **Impl√©mentation :** Comparaison de la distribution de `body_mass` en base (Training) vs flux entrants (Production simul√©e).
* **Alerte :** Si `P-Value < 0.05`, le Dashboard affiche "üî¥ DRIFT DETECTED".

### 6.2 Monitoring de la Performance

Visualisation en temps r√©el de la **Matrice de Confusion**, comparant les √©tiquettes r√©elles (`label`) stock√©es dans MongoDB aux pr√©dictions (`prediction`).

---

## 7. Benchmarks & Analyse de Performance

Latence moyenne de lecture mesur√©e sur 1 000 it√©rations s√©quentielles :

| Technologie | Type | Latence Moyenne | Throughput Estim√© | Cas d'usage id√©al |
| --- | --- | --- | --- | --- |
| **Redis** | In-Memory | **0.18 ms** | ~5,600 req/s | Cache API, Session utilisateur |
| **MongoDB** | Document | **0.35 ms** | ~2,800 req/s | Backend Web, Profils utilisateurs |
| **Cassandra** | Columnar | **1.52 ms** | ~650 req/s | Historique, Time-Series, IoT |

**Analyse :** Redis domine gr√¢ce √† l'absence d'I/O disque, essentiel pour la couche "V√©locit√©". Cassandra, bien que plus lent en lecture unitaire, offre une scalabilit√© lin√©aire en √©criture pour les volumes massifs.

---

## 8. Conclusion & Perspectives de Scalabilit√©

Ce projet valide une architecture Lambda compl√®te, allant de l'ingestion √† l'analyse pr√©dictive.

**Points Forts :**

1. **Couverture Compl√®te :** Int√®gre Statistiques Descriptives, R√©gression, et Classification.
2. **R√©silience :** Architecture d√©coupl√©e (l'API survit si Spark tombe).
3. **Automatisation :** D√©ploiement `docker-compose` et interface "No-Code" (Streamlit).
